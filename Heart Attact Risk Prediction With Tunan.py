# -*- coding: utf-8 -*-
"""HeartAttackRiskPrediction_group08_CSE422_sec01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-ukP1ikyDzKkJNRMEJSxQfG9SFKdfHzh

# Heart Attack Risk Prediction Project
_______________________________________

https://www.kaggle.com/datasets/iamsouravbanerjee/heart-attack-prediction-dataset
"""

#importing necessary libraries
import pandas as pd
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

heartdata = pd.read_csv('/content/drive/MyDrive/CSE422 Project group 8/heart_attack_prediction_dataset.csv')
heartdata.head(10)

""" Removing Null values / Handling Missing data"""

heartdata.shape

heartdata.dtypes

heartdata.head()

heartdata.isnull()

heartdata.isnull().sum()

"""## Inserting Random null values

Our dataset didn't have any null values, so I am inserting 16,000 random null values.
"""

np.random.seed(42)
# Insert 16,000 random null values (excluding some)
for _ in range(16000):
    random_row_index = np.random.randint(0, len(heartdata))
    random_column = np.random.choice(heartdata.columns[~heartdata.columns.isin(['Age', 'Sex', 'Cholesterol', 'Blood Pressure',
       'Heart Rate', 'Diabetes','BMI', 'Triglycerides','Hemisphere', 'Diet','Heart Attack Risk'])])
    heartdata.at[random_row_index, random_column] = np.nan

total_null_values = heartdata.isnull().sum().sum()
print(f"Total number of null values in the dataset: {total_null_values}")

"""## Removing Null values / Handling Missing data

"""

heartdata.isnull().sum()

heartdata.isnull()

"""##Droping Irrelivant features- Feature selection"""

heartdata = heartdata.drop(['Patient ID', 'Continent', 'Country',], axis = 1)
heartdata.shape

"""##Droping null rows"""

# Check how many values are missing in the Previous Heart Problems column
print("Number of rows with null values in Previous Heart Problems column: ", heartdata['Previous Heart Problems'].isnull().sum())

# Subset the heartdata dataset
heartdata_subset = heartdata[heartdata['Previous Heart Problems'].notnull()]

print("Shape of dataframe before dropping:", heartdata.shape)
heartdata = heartdata.dropna(axis = 0, subset = ['Previous Heart Problems'])
print("Shape after dropping:", heartdata.shape)

# Check how many values are missing in the Medication Use column
print("Number of rows with null values in Medication Use column: ", heartdata['Medication Use'].isnull().sum())

# Subset the heartdata dataset
heartdata_subset = heartdata[heartdata['Medication Use'].notnull()]

print("Shape of dataframe before dropping:", heartdata.shape)
heartdata = heartdata.dropna(axis = 0, subset = ['Medication Use'])
print("Shape after dropping:", heartdata.shape)

# Check how many values are missing in the Stress Level column
print("Number of rows with null values in Stress Level column: ", heartdata['Stress Level'].isnull().sum())

# Subset the heartdata dataset
heartdata_subset = heartdata[heartdata['Stress Level'].notnull()]

print("Shape of dataframe before dropping:", heartdata.shape)
heartdata = heartdata.dropna(axis = 0, subset = ['Stress Level'])
print("Shape after dropping:", heartdata.shape)

"""## Imputing missing Values"""

# Convert missing values to mean
columns_to_mean = heartdata[['Sedentary Hours Per Day','Physical Activity Days Per Week', 'Sleep Hours Per Day',
                             'Income', 'Exercise Hours Per Week']]
columns_to_mean = columns_to_mean.fillna(columns_to_mean.mean())


#Binary Data: 'Family History','Smoking', 'Obesity','Alcohol Consumption'
# Convert remaining missing values to binary 0
heartdata = heartdata.fillna(0)

heartdata.isnull().sum()

heartdata.columns



"""## Feature Engineering

## Encoding categorical variables - binary
"""

heartdata['Sex'].unique()

from sklearn.preprocessing import LabelEncoder

# Set up the LabelEncoder object
enc = LabelEncoder()

# Apply the encoding to the "Sex" column
heartdata['Sex_new'] = enc.fit_transform(heartdata['Sex'])

# Compare the two columns
print(heartdata[['Sex', 'Sex_new']].head())

heartdata['Hemisphere'].unique()

from sklearn.preprocessing import LabelEncoder

# Set up the LabelEncoder object
enc = LabelEncoder()

# Apply the encoding to the "Hemisphere" column
heartdata['Hemisphere_new'] = enc.fit_transform(heartdata['Hemisphere'])

# Compare the two columns
print(heartdata[['Hemisphere', 'Hemisphere_new']].head())

"""We may also encode/map a certain class to a specific code by using the `map()` function."""

heartdata['Diet_new'] = heartdata['Diet'].map({'Healthy':2,'Unhealthy':0,'Average':1})
print(heartdata[['Diet', 'Diet_new']].head())

"""## Encoding categorical variables - one-hot encoding"""

# Transform the Diet_desc column
Diet_enc = pd.get_dummies(heartdata['Diet'])

# Take a look at the encoded columns
Diet_enc.head()

heartdata['Diet'].head(100)

"""##Feature Engineering"""

heartdata[['Systolic', 'Diastolic']] = heartdata['Blood Pressure'].str.split('/', expand=True)
heartdata['Systolic'] = heartdata['Systolic'].astype(int)
heartdata['Diastolic'] = heartdata['Diastolic'].astype(int)
heartdata.drop(columns=['Blood Pressure'], inplace=True)

heartdata.head()

"""# Feature Selection

## Selecting relevant features
"""

heartdata.columns

to_drop = ["Income",'Sex','Hemisphere','Diet']
heartdata = heartdata.drop(to_drop, axis=1)
heartdata.head(10)

"""## Checking for correlated features"""

import pandas as pd
numeric_features = heartdata.drop(columns=['Heart Attack Risk']).select_dtypes(include=['number'])
correlation_matrix = numeric_features.corr()
abs_correlation_matrix = correlation_matrix.abs()
mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
masked_correlation_matrix = abs_correlation_matrix.mask(mask)
threshold = 0.7
highly_correlated_pairs = (masked_correlation_matrix > threshold).stack()
correlated_features = highly_correlated_pairs[highly_correlated_pairs].index.tolist()
print("Pairs of highly correlated features:")
for pair in correlated_features:
    print(pair)

import matplotlib.pyplot as plt
import seaborn as sns
_feature = 'Heart Attack Risk'
selected = heartdata.columns[heartdata.columns != _feature]
sampled_data = heartdata.groupby(_feature, group_keys=False).apply(lambda x: x.sample(min(len(x), 50)))
correlation_matrix = sampled_data[selected].corr(numeric_only=True)
plt.figure(figsize=(20, 15))
sns.heatmap(correlation_matrix, cmap='YlGnBu', vmin=-1, vmax=1, annot=True)
plt.show()

#Correlation heatmap of 5 random features
import random
_feature = 'Heart Attack Risk'
selec_col =heartdata.columns[heartdata.columns != _feature]
ran_col = random.sample(selec_col.tolist(), 5)
sampled_data =heartdata.groupby(_feature, group_keys=False).apply(lambda x: x.sample(min(len(x), 50)))
correlation_matrix = sampled_data[ran_col].corr(numeric_only=True)
plt.figure(figsize=(10, 5))
sns.heatmap(correlation_matrix, cmap='YlGnBu', vmin=-1, vmax=1, annot=True)
plt.show()
#coolwarm



"""##**Seperating Trainning Data and Test Data**"""

from sklearn.model_selection import train_test_split

X = heartdata.drop('Heart Attack Risk', axis=1)
Y = heartdata['Heart Attack Risk']

# 70/30 split for training and testing data
train_set, test_set = train_test_split(heartdata, test_size=0.3, random_state=42,stratify=Y)

X_train = train_set.drop('Heart Attack Risk', axis=1)
Y_train = train_set['Heart Attack Risk']

X_test = test_set.drop('Heart Attack Risk', axis=1)
Y_test = test_set['Heart Attack Risk']

print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
sns.countplot(x='Heart Attack Risk', data=train_set)
plt.title('Training Set - Heart Attack Risk Distribution')
plt.show()

"""Standard Scaler:"""

from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier()

knn.fit(X_train, Y_train)

print("Test set accuracy: {:.2f}".format(knn.score(X_test, Y_test)))

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled_d = scaler.fit_transform(X_train)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_train)

X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
knn.fit(X_train_scaled,Y_train)
print("KNN test accuracy: {:.2f}".format(knn.score(X_test_scaled, Y_test)))

heartdata.head()

"""## **Trainning and Prediction Accuracy:**

##**Model 1: Decision Tree (RandomForestClassifier)**
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

model = RandomForestClassifier(n_estimators=20, random_state=42)
model.fit(X_train, Y_train)

Y_pred = model.predict(X_test)

accuracy = accuracy_score(Y_test, Y_pred)
print(f'Accuracy: {accuracy:.2f}')

print(classification_report(Y_test, Y_pred))

"""Visualization:"""

from sklearn.metrics import confusion_matrix
conf_matrix = confusion_matrix(Y_test, Y_pred)
plt.figure(figsize=(10, 5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
plt.title('Confusion Matrix For RandomForrestClassifier')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

class_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)
plt.figure(figsize=(10, 5))
sns.barplot(x=model.classes_, y=class_accuracy, color='skyblue')
plt.title('Prediction Accuracy - Decision Tree')
plt.xlabel('Heart Attack Risk')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.show()

"""##**Model 2: K-Nearest Neighbors (KNeighborsClassifier)**"""

from sklearn.neighbors import KNeighborsClassifier

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, Y_train)
Y_pred_knn = knn_model.predict(X_test)

accuracy_knn = accuracy_score(Y_test, Y_pred_knn)
print(f'K-Nearest Neighbors Accuracy: {accuracy_knn:.2f}')

print('Classification Report for K-Nearest Neighbors:')
print(classification_report(Y_test, Y_pred_knn))

"""Visualization:"""

from sklearn.metrics import confusion_matrix
conf_matrix = confusion_matrix(Y_test, Y_pred_knn)

plt.figure(figsize=(10, 5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
plt.title('Confusion Matrix For KNeighborsClassifier')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

class_accuracy_knn = conf_matrix.diagonal() / conf_matrix.sum(axis=1)
plt.figure(figsize=(10, 5))
sns.barplot(x=knn_model.classes_, y=class_accuracy_knn, color='skyblue')
plt.title('Prediction Accuracy - K-Nearest Neighbors')
plt.xlabel('Heart Attack Risk')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.show()

"""##**Model 3: Support Vector Machine(SVC)**"""

from sklearn.svm import SVC
svm_model = SVC()
svm_model.fit(X_train, Y_train)
Y_pred_svm = svm_model.predict(X_test)
accuracy_svm = accuracy_score(Y_test, Y_pred_svm)
print(f'Support Vector Machine Accuracy: {accuracy_svm:.2f}')
print('Classification Report for Support Vector Machine:')
print(classification_report(Y_test, Y_pred_svm))

from sklearn.metrics import confusion_matrix
conf_matrix = confusion_matrix(Y_test, Y_pred_svm)
plt.figure(figsize=(10, 5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
plt.title('Confusion Matrix FOR SVM')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

class_accuracy_knn = conf_matrix.diagonal() / conf_matrix.sum(axis=1)
plt.figure(figsize=(10, 5))
sns.barplot(x=knn_model.classes_, y=class_accuracy_knn, color='skyblue')
plt.title('Prediction Accuracy - Support Vector Machine')
plt.xlabel('Heart Attack Risk')
plt.ylabel('Accuracy')
plt.ylim(0,1)
plt.show()

import matplotlib.pyplot as plt

# Define the models
models = {
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'Decision Tree Classifier': RandomForestClassifier(),
    'Support Vector Machine': SVC()
}

# Train each model and make predictions
results = {}
for name, model in models.items():
    model.fit(X_train, Y_train)
    Y_pred = model.predict(X_test)
    accuracy = accuracy_score(Y_test, Y_pred)
    results[name] = accuracy

# Visualize the results
plt.figure(figsize=(10, 5))
plt.bar(results.keys(), results.values(), color='darkblue')
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Accuracy of Different Models on Test Data')
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Define the models
models = {
    'Support Vector Machine': SVC(),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'Decision Tree Classifier': RandomForestClassifier()
}

# Train and evaluate each model
for name, model in models.items():
    model.fit(X_train, Y_train)
    Y_pred = model.predict(X_test)
    accuracy = accuracy_score(Y_test, Y_pred)
    print(f"{name}: Accuracy = {accuracy:.2f}")